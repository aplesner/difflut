{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fddd7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aplesner/code/difflut/difflut/nodes/__init__.py:7: RuntimeWarning: CUDA extension 'efd_cuda' not available. DWNNode will use slower CPU fallback. For better performance, compile the CUDA extension using: 'cd difflut && python setup.py install'. To suppress this warning: warnings.filterwarnings('ignore', category=RuntimeWarning, module='difflut.nodes.dwn_node')\n",
      "  from .dwn_node import DWNNode\n",
      "/home/aplesner/code/difflut/difflut/nodes/__init__.py:9: RuntimeWarning: CUDA extension 'probabilistic_cuda' not available. ProbabilisticNode will use slower CPU fallback. For better performance, compile the CUDA extension using: 'cd difflut && python setup.py install'. To suppress this warning: warnings.filterwarnings('ignore', category=RuntimeWarning, module='difflut.nodes.probabilistic_node')\n",
      "  from .probabilistic_node import ProbabilisticNode\n",
      "/home/aplesner/code/difflut/difflut/nodes/__init__.py:10: RuntimeWarning: CUDA extension 'probabilistic_stable_cuda' not available. ProbabilisticStableNode will use slower CPU fallback. For better performance, compile the CUDA extension using: 'cd difflut && python setup.py install'. To suppress this warning: warnings.filterwarnings('ignore', category=RuntimeWarning, module='difflut.nodes.probabilistic_stable_node')\n",
      "  from .probabilistic_stable_node import ProbabilisticStableNode\n",
      "/home/aplesner/code/difflut/difflut/nodes/__init__.py:13: RuntimeWarning: CUDA extension 'hybrid_cuda' not available. HybridNode will use slower CPU fallback. For better performance, compile the CUDA extension using: 'cd difflut && python setup.py install'. To suppress this warning: warnings.filterwarnings('ignore', category=RuntimeWarning, module='difflut.nodes.hybrid_node')\n",
      "  from .hybrid_node import HybridNode\n",
      "/home/aplesner/code/difflut/difflut/nodes/__init__.py:14: RuntimeWarning: CUDA extension 'fourier_cuda' not available. FourierNode will use slower CPU fallback. For better performance, compile the CUDA extension using: 'cd difflut && python setup.py install'. To suppress this warning: warnings.filterwarnings('ignore', category=RuntimeWarning, module='difflut.nodes.fourier_node')\n",
      "  from .fourier_node import FourierNode\n",
      "/home/aplesner/code/difflut/difflut/nodes/__init__.py:15: RuntimeWarning: CUDA extension 'dwn_stable_cuda' not available. DWNStableNode will use slower CPU fallback. For better performance, compile the CUDA extension using: 'cd difflut && python setup.py install'. To suppress this warning: warnings.filterwarnings('ignore', category=RuntimeWarning, module='difflut.nodes.dwn_stable_node')\n",
      "  from .dwn_stable_node import DWNStableNode\n"
     ]
    }
   ],
   "source": [
    "# Convolutional kernel for LUT-based models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from difflut.models.feedforward import feedforward_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f42a02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalLUTLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional layer using LUT-based nodes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            tree_depth: int,\n",
    "            in_channels: int,\n",
    "            out_channels: int,\n",
    "            receptive_field: int | tuple[int, int] = 5,\n",
    "            stride: int | tuple[int, int] = 1,\n",
    "            padding: int | tuple[int, int] = 0,\n",
    "            node_type: str = 'dwn',\n",
    "            layer_type: str = 'random',\n",
    "            n_inputs_per_node: int = 6,\n",
    "            # node_kwargs: dict | None = None\n",
    "            ):\n",
    "        super(ConvolutionalLUTLayer, self).__init__()\n",
    "        self.tree_depth = tree_depth\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.receptive_field = self._pair(receptive_field)\n",
    "        self.stride = self._pair(stride)\n",
    "        self.padding = self._pair(padding)\n",
    "        self.node_type = node_type\n",
    "        self.layer_type = layer_type\n",
    "        self.n_inputs_per_node = n_inputs_per_node\n",
    "        # self.node_kwargs = node_kwargs if node_kwargs is not None else {}\n",
    "\n",
    "        # Create trees (one for each output channel)\n",
    "        # Each tree is a small feedforward network of LUT nodes\n",
    "        hidden_layers = [self.n_inputs_per_node ** (self.tree_depth - i) for i in range(self.tree_depth + 1)]\n",
    "        self.trees = nn.ModuleList()\n",
    "        for _ in range(out_channels):\n",
    "            tree = feedforward_core(\n",
    "                input_size=in_channels * self.receptive_field[0] * self.receptive_field[1],\n",
    "                hidden_sizes=hidden_layers,\n",
    "                node_type=self.node_type,\n",
    "                layer_type=self.layer_type,\n",
    "                n_inputs=self.n_inputs_per_node,\n",
    "                # node_kwargs=self.node_kwargs\n",
    "            )\n",
    "            self.trees.append(tree)\n",
    "        \n",
    "        # For convolution, we use the unfold operation\n",
    "        self.unfold = nn.Unfold(kernel_size=receptive_field, padding=0, stride=1)\n",
    "\n",
    "    def _pair(self, x: int | tuple[int, int]) -> tuple[int, int]:\n",
    "        if isinstance(x, int):\n",
    "            return (x, x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Extract patches: (batch, patch_size, num_patches)\n",
    "        patches = self.unfold(x)\n",
    "        num_patches = patches.shape[2]\n",
    "        \n",
    "        # Reshape to (batch*num_patches, patch_size)\n",
    "        patches = patches.transpose(1, 2).contiguous()\n",
    "        patches = patches.view(-1, self.receptive_field * self.in_channels)\n",
    "\n",
    "        # Process each patch through each tree\n",
    "        output = [tree(patches) for tree in self.trees]\n",
    "        output = torch.stack(output, dim=1)  # (batch*num_patches, out_channels)\n",
    "\n",
    "        output = output.view(batch_size, num_patches, self.out_channels)\n",
    "        output = output.transpose(1, 2)  # (batch, out_channels, num_patches)\n",
    "        \n",
    "        # Calculate output spatial dimensions\n",
    "        out_h = (x.shape[2] + 2 * self.padding[0] - self.receptive_field[0]) // self.stride[0] + 1\n",
    "        out_w = (x.shape[3] + 2 * self.padding[1] - self.receptive_field[1]) // self.stride[1] + 1\n",
    "\n",
    "        output = output.view(batch_size, self.out_channels, out_h, out_w)\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f45448e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building DiffLUT model:\n",
      "  Node type: dwn\n",
      "  Input size: 25\n",
      "  Hidden layers: [216, 36, 6, 1]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "difflut.nodes.dwn_node.DWNNode() got multiple values for keyword argument 'input_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m conv_lut_layer = \u001b[43mConvolutionalLUTLayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtree_depth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreceptive_field\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnode_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdwn\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrandom\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_inputs_per_node\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mConvolutionalLUTLayer.__init__\u001b[39m\u001b[34m(self, tree_depth, in_channels, out_channels, receptive_field, stride, padding, node_type, layer_type, n_inputs_per_node)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mself\u001b[39m.trees = nn.ModuleList()\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(out_channels):\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     tree = \u001b[43mfeedforward_core\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreceptive_field\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreceptive_field\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_inputs_per_node\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# node_kwargs=self.node_kwargs\u001b[39;49;00m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mself\u001b[39m.trees.append(tree)\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# For convolution, we use the unfold operation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/difflut/difflut/models/feedforward.py:63\u001b[39m, in \u001b[36mfeedforward_core.__init__\u001b[39m\u001b[34m(self, input_size, hidden_sizes, node_type, layer_type, n_inputs)\u001b[39m\n\u001b[32m     56\u001b[39m node_kwargs = {\n\u001b[32m     57\u001b[39m     \u001b[33m'\u001b[39m\u001b[33minput_dim\u001b[39m\u001b[33m'\u001b[39m: n_inputs,\n\u001b[32m     58\u001b[39m     \u001b[33m'\u001b[39m\u001b[33moutput_dim\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m,\n\u001b[32m     59\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlayer_size\u001b[39m\u001b[33m'\u001b[39m: hidden_size\n\u001b[32m     60\u001b[39m }\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Create layer with proper node_kwargs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m layer = \u001b[43mlayer_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurrent_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnode_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnode_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_kwargs\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mself\u001b[39m.hidden_layers.append(layer)\n\u001b[32m     70\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m â†’ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/difflut/difflut/layers/random_layer.py:34\u001b[39m, in \u001b[36mRandomLayer.__init__\u001b[39m\u001b[34m(self, input_size, output_size, node_type, n, node_kwargs, seed)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mself\u001b[39m.seed = seed\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Initialize parent\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Initialize the random mapping\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mself\u001b[39m._init_mapping()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/difflut/difflut/layers/base_layer.py:26\u001b[39m, in \u001b[36mBaseLUTLayer.__init__\u001b[39m\u001b[34m(self, input_size, output_size, node_type, n, node_kwargs)\u001b[39m\n\u001b[32m     24\u001b[39m node_kwargs_i = node_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Use new interface: input_dim and output_dim as lists\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m node = node_type(input_dim=[n], output_dim=[\u001b[32m1\u001b[39m], **node_kwargs_i)\n\u001b[32m     27\u001b[39m \u001b[38;5;28mself\u001b[39m.nodes.append(node)\n",
      "\u001b[31mTypeError\u001b[39m: difflut.nodes.dwn_node.DWNNode() got multiple values for keyword argument 'input_dim'"
     ]
    }
   ],
   "source": [
    "conv_lut_layer = ConvolutionalLUTLayer(\n",
    "    tree_depth=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    receptive_field=5,\n",
    "    stride=1,\n",
    "    padding=0,\n",
    "    node_type='dwn',\n",
    "    layer_type='random',\n",
    "    n_inputs_per_node=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8523ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
