###############################################################################
# PyTorch Universal Container for Heterogeneous GPU Cluster
# Supports:
# - NVIDIA A100 (8.0), A6000 (8.6)
# - RTX 3090 (8.6), Titan RTX (7.5), Titan XP (6.1)
# - V100 (7.0), RTX 2080 Ti (7.5)
# Base Image: pytorch/pytorch:2.4.0-cuda12.4-cudnn9-runtime
###############################################################################
Bootstrap: docker
From: pytorch/pytorch:2.4.0-cuda12.4-cudnn9-devel
Stage: build

%setup
    # Copy entire difflut package (including nested structure and setup.py)
    cp -r difflut ${APPTAINER_ROOTFS}/opt/

%post
    ##################################################
    # Essential System Dependencies
    ##################################################
    apt-get update && apt-get install -y \
        g++ \
        make \
        cmake \
        ccache \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

    ##################################################
    # CUDA Architecture Configuration & ccache
    ##################################################
    # We omit the 3090s, A100s and A6000s for faster compile times
    # If you want to include them, uncomment the line below
    # export TORCH_CUDA_ARCH_LIST="6.1;7.0;7.5"
    export TORCH_CUDA_ARCH_LIST="6.1;7.0;7.5;8.0;8.6"
    export CUDA_HOME=/usr/local/cuda
    export LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:$LD_LIBRARY_PATH

    # Setup ccache for faster rebuilds
    export PATH=/usr/lib/ccache:$PATH
    export CCACHE_DIR=/tmp/ccache
    export CCACHE_MAXSIZE=5G
    mkdir -p /tmp/ccache

    ##################################################
    # Python Packages
    ##################################################
    pip3 install --no-cache-dir --upgrade pip
    pip3 install --no-cache-dir \
        tqdm \
        scikit-learn \
        numpy \
        matplotlib \
        pandas \
        wandb \
        omegaconf \
        hydra-core \
        tonic \
        aedat \
        lightning \
        jupyterlab \
        ipywidgets \
        notebook \
        ipykernel \
        pydantic \
        difflogic
        
    # Verify the hydra installation
    python3 -c "import hydra; print('Hydra version:', hydra.__version__)"

    ##################################################
    # Install DiffLUT with CUDA Extensions
    ##################################################
    echo "=============================================="
    echo "Building DiffLUT with CUDA extensions..."
    echo "=============================================="

    cd /opt/difflut
    echo "DEBUG: Contents of /opt/difflut:"
    ls -la
    echo "DEBUG: Checking outer __init__.py:"
    cat __init__.py
    echo "DEBUG: Checking inner __init__.py version:"
    grep "__version__" difflut/__init__.py || echo "No __version__ found in inner __init__.py"

    # Set MAX_JOBS to number of CPU cores minus 2 for parallel build
    export MAX_JOBS=$(( $(nproc) - 2 ))
    [ $MAX_JOBS -lt 1 ] && MAX_JOBS=1
    echo "Using MAX_JOBS=$MAX_JOBS for parallel build"

    # Install in regular mode (not editable) to avoid symlink issues
    pip3 install --no-cache-dir --no-build-isolation -vv .

    echo "=============================================="
    echo "DiffLUT installation complete"
    echo "DEBUG: Installed package location:"
    python3 -c "import difflut; print('Module location:', difflut.__file__)"
    echo "DEBUG: Contents of installed __init__.py:"
    python3 -c "import difflut; import os; print(open(difflut.__file__).read()[:500])"
    echo "Testing import:"
    python3 -c "import difflut; print('Version:', difflut.__version__); from difflut.nodes import LinearLUTNode; print('Import successful')"
    echo "ccache stats:"
    ccache -s
    echo "=============================================="
     
    ##################################################
    # Prepare artifacts
    ##################################################
    mkdir -p /opt/artifacts/lib/python3.11/site-packages
    cp -r /opt/conda/lib/python3.11/site-packages/* /opt/artifacts/lib/python3.11/site-packages/

   echo "=============================================="

%environment
    ##################################################
    # Environment Configuration
    ##################################################
    export LC_ALL=C.UTF-8
    export PATH=/opt/conda/bin:$PATH
    export CUDA_HOME=/usr/local/cuda
    export LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:$LD_LIBRARY_PATH


###############################################################################
# Final Runtime Image
###############################################################################

Bootstrap: docker
From: pytorch/pytorch:2.4.0-cuda12.4-cudnn9-runtime
Stage: final

%files from build
    /opt/artifacts /opt/artifacts

%post
    ##################################################
    # Install Python packages from build stage
    ##################################################
    cp -r /opt/artifacts/lib/python3.11/site-packages/* /opt/conda/lib/python3.11/site-packages/

    ##################################################
    # Cleanup and permissions
    ##################################################
    rm -rf /opt/artifacts
    chmod -R a+r /opt/conda/lib/python3.11/site-packages
    # Update shared library cache
    
    # Verify DiffLUT installation
    echo "=============================================="
    echo "DiffLUT installation complete"
    echo "DEBUG: Installed package location:"
    python3 -c "import difflut; print('Module location:', difflut.__file__)"
    echo "DEBUG: Contents of installed __init__.py:"
    python3 -c "import difflut; import os; print(open(difflut.__file__).read()[:500])"
    echo "Testing import:"
    python3 -c "import difflut; print('Version:', difflut.__version__); from difflut.nodes import LinearLUTNode; print('Import successful')"
    echo "=============================================="
    ldconfig  


%environment
    ##################################################
    # Environment Configuration
    ##################################################
    export LC_ALL=C.UTF-8
    export PATH=/opt/conda/bin:$PATH
    export CUDA_HOME=/usr/local/cuda
    export LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:$LD_LIBRARY_PATH

%runscript
    ##################################################
    # Startup Information
    ##################################################
    echo "===================================================================="
    echo "PyTorch Universal Container"
    echo "Supported CUDA Architectures: 6.1, 7.0, 7.5, 8.0, 8.6"
    echo "--------------------------------------------------------------------"
    echo "Python version: $(python --version)"
    echo "$(python -c 'import torch; print(f"PyTorch version: {torch.__version__}", "CUDA available: {torch.cuda.is_available()}", "CUDA version: {torch.version.cuda}", "GPU detected: {torch.cuda.get_device_name(0)}", sep="\n")')"
    echo "===================================================================="
    echo "Usage: singularity exec --nv --bind <host_path>:<container_path> <image.sif> python script.py"

    echo "Starting Jupyter Lab..."
    python3 -m notebook --no-browser --port 5998 --ip $(hostname -f)
